

12/25/24 - o1 preview

# AI and Group Decision Making: An Information Processing Perspective
*Thomas E. Gorman, Torsten Reimer*

## Introduction

- **Widespread Integration of AI in Group Decision-Making**:
  - AI is increasingly central in group decision-making across various domains, such as healthcare, finance, education, and policymaking.
    - *Cited works*:
      - **BaniHani et al. (2024); Burton et al. (2024); Carter & Wynne (2024)**: Illustrate the wide adoption of AI in diverse fields.

- **Opportunities and Challenges of Human-AI Collaboration**:
  - Opportunities:
    - Enhanced information processing efficiency.
    - Improved decision accuracy.
    - Streamlined communication within teams.
  - Challenges:
    - Issues of trust and over-reliance.
    - Susceptibility to cognitive biases.
    - Erosion of critical thinking skills.
    - Lack of transparency in AI algorithms.
    - Ethical concerns regarding accountability and fairness.

- **Evolution of AI Roles in Group Settings**:
  - From basic decision-support tools to sophisticated collaborative partners.
  - *Large Language Models (LLMs)*:
    - Facilitate collective intelligence.
    - Synthesize information.
    - Generate alternative solutions.
    - Mediate group discussions.
  
- **Context-Dependent Impact of AI on Group Performance**:
  - Human-AI collaboration can lead to performance augmentation or decrements.
    - *Cited work*:
      - **Vaccaro et al. (2024)**: Meta-analysis revealing that the impact of human-AI collaboration varies depending on the task and interaction design.

- **Adoption of the Information Processing Framework**:
  - Using the framework to examine AI-assisted group decision-making.
    - *Cited work*:
      - **Hinsz et al. (1997)**: Provides a structured method to analyze interactions between AI systems and human cognitive processes in decision-making.

- **Key Questions Within the Framework**:
  - **Inputs**: How does AI influence the way groups search for, gather, and share information?
  - **Processing**: In what ways do AI systems affect the interpretation and integration of information within the group?
  - **Outputs**: How do AI recommendations influence the group’s final decisions and actions?

---

## Inputs

### Group Member Roles

- **Importance of Role Assignment in Teams**:
  - Critical for maximizing group decision-making effectiveness.
  - Particularly significant in human-AI teams where members need to learn who is best suited for specific roles.

- **Task Allocation Between Humans and AI Agents**:
  - *Cited work*:
    - **Marjieh et al. (2024)**:
      - Explores human task allocation within teams comprising humans and AI agents.
      - Experimental paradigm:
        - Participants allocated visual, auditory, and lexical tasks between themselves and two AI agents.
        - Each AI agent had high competence in one task type (70% success rate) and low competence in others (15% success rate).
      - *Relevance*: Demonstrates mechanisms by which individuals discern and act upon the strengths of team members, including AI agents, to optimize performance.

- **Distinct Nature of Human-Autonomy Teams (HATs)**:
  - *Cited work*:
    - **McNeese et al. (2023)**:
      - Argues that HATs should be recognized as distinct from traditional human teams.
      - Emphasizes leveraging the unique capabilities of AI agents rather than replicating human-human team dynamics.
      - Proposes research trajectories:
        - Exploring diverse teaming models.
        - Redefining roles for AI teammates.
        - Expanding communication modalities.
        - Focusing on AI behavior design.
        - Developing specialized training.
        - Emphasizing teamwork in AI design.
      - *Relevance*: Highlights the necessity of adjusting team composition and role assignment approaches when integrating AI agents.

---

- **Expansion of AI Roles Due to Advances in LLMs**:
  - AI agents can now serve as mediators, devil’s advocates, and active discussion participants in group decision-making.

- **AI as a Devil’s Advocate to Foster Critical Engagement**:
  - *Cited work*:
    - **Chiang et al. (2024)**:
      - Investigated the use of LLMs as devil’s advocates in AI-assisted group decision-making.
      - Experimental task:
        - Participants trained individually on the relationship between defendant profiles and recidivism.
        - In group discussions, participants reviewed novel defendant profiles and made group assessments.
        - Introduced "RiskComp," an AI model providing biased recommendations against certain defendants.
        - Employed an LLM-based devil’s advocate to challenge biases.
        - Four variants of the devil’s advocate were tested:
          - Target of objection: Challenging either AI recommendations or majority group opinions.
          - Level of interactivity: Static comments vs. dynamic engagement.
      - Findings:
        - The dynamic devil’s advocate improved decision accuracy and discernment regarding when to trust AI advice.
      - *Relevance*: Demonstrates how AI can mitigate biases and enhance critical thinking in group decision-making.

- **Additional Works Related to Group Member Roles**:
  - *(Details not provided, but implied relevance to this section)*:
    - **A. Kumar et al. (2024)**
    - **Lu et al. (2024)**
    - **McNeese et al. (2023)**

---

## Information Processing

### Information Search

- **Transformation of Information Search by AI and LLMs**:
  - Augments data retrieval and synthesis.
  - Fosters idea generation and creative discovery.

#### AI-Assisted Data Retrieval and Synthesis

- **Enhanced Data Processing and Insight Generation**:
  - *Cited work*:
    - **Bouschery et al. (2023)**:
      - LLMs process vast datasets, identifying connections and patterns beyond human capacity.
      - *Relevance*: Illustrates how LLMs enhance information gathering and synthesis.

- **Influence of Individual Differences on AI Interaction**:
  - *Cited work*:
    - **Flores et al. (2024)**:
      - Explores how computational thinking skills affect user interaction with LLMs.
      - Users with higher creativity and algorithmic thinking engage more effectively with AI-generated content.
      - *Relevance*: Highlights the role of individual differences in maximizing AI's potential.

- **Strategic Use of AI in Professional Workflows**:
  - *Cited work*:
    - **Yen et al. (2024)**:
      - Examines how programmers navigate between traditional web search and generative AI tools.
      - Strategic selection based on task familiarity and goal clarity.
      - *Relevance*: Demonstrates the integration of AI tools in professional practices.

- **Bridging Knowledge Gaps in Interdisciplinary Research**:
  - *Cited work*:
    - **Zheng et al. (2024)**:
      - Introduces "DiscipLink," which uses LLMs to generate exploratory questions across disciplines.
      - Expands queries with field-specific terminology and extracts themes from retrieved papers.
      - *Relevance*: Shows how AI facilitates interdisciplinary collaboration by overcoming knowledge barriers.

- **Advanced Techniques Enhancing AI Capabilities**:
  - *Cited works*:
    - **Si et al. (2024); Wang et al. (2024)**:
      - Discuss retrieval-augmented generation (RAG) allowing LLMs to access and process real-time information.
      - *Relevance*: Enhances accuracy and relevance of AI outputs for decision-making.

- **Empowering Decision-Makers with Synthesized Insights**:
  - *Cited work*:
    - **Burton et al. (2024)**:
      - Emphasizes AI's role in providing comprehensive, synthesized insights from diverse sources.
      - *Relevance*: Underlines AI's importance in informed decision-making across various fields.

- **Natural Language Interfaces and User Experience**:
  - *Cited work*:
    - **Spatharioti et al. (2023)**:
      - Highlights how LLM-based search tools streamline complex queries and provide detailed responses.
      - Leads to increased efficiency and user satisfaction.
      - *Relevance*: Demonstrates user benefits of AI-enhanced information retrieval.

- **Risks of Overreliance and Decreased Critical Evaluation**:
  - *Cited works*:
    - **Anderl et al. (2024)**:
      - Points out that ease of use can lead to overreliance on inaccurate information.
      - Decreased critical evaluation, especially with conversational AI.
    - **Sharma et al. (2024)**:
      - Discusses the formation of "generative echo chambers" limiting exposure to diverse perspectives.
    - **Stadler et al. (2024)**:
      - Notes that reduced cognitive load may come at the cost of deeper learning and sophisticated reasoning.
      - *Relevance*: Highlights the need for careful design to mitigate risks associated with AI-mediated information search.

#### AI in Idea Generation and Creative Discovery

- **AI as a Catalyst for Creativity**:
  - *Cited work*:
    - **Bouschery et al. (2023)**:
      - LLMs offer alternative perspectives, challenge assumptions, and propose unexpected connections.
      - *Relevance*: AI's role in enhancing creative processes.

- **Selective Information Sharing Enhancing Collective Intelligence**:
  - *Cited work*:
    - **Ueshima & Takikawa (2024)**:
      - In structured tasks, AI agents amplify group performance through selective information sharing.
      - *Relevance*: AI's contribution to group idea generation and problem-solving.

- **Comparative Studies of Human and AI-Generated Ideas**:
  - *Strengths of AI*:
    - *Cited works*:
      - **Joosten et al. (2024); Meincke et al. (2024); Si et al. (2024)**:
        - LLMs generate ideas with higher average quality and novelty.
        - In some cases, surpass human experts.
      - *Relevance*: Demonstrates AI's capability in producing valuable and innovative ideas.
  - *Limitations of AI*:
    - **Joosten et al. (2024)**:
      - AI-generated ideas may have lower feasibility.
    - **Meincke et al. (2024)**:
      - Potential for reduced idea diversity.
      - *Relevance*: Points out areas where AI-generated ideas may fall short.

- **Enhancing AI Creativity Through Prompt Engineering**:
  - *Cited work*:
    - **Boussioux et al. (2024)**:
      - Strategic prompt engineering, such as differentiated search, enhances the novelty of AI-generated solutions.
      - *Relevance*: Importance of human-guided inputs in maximizing AI's creative output.

- **Impact of AI Interaction on Human Creativity**:
  - **Positive Influence**:
    - *Cited work*:
      - **Ashkinaze et al. (2024)**:
        - Exposure to AI-generated ideas increases diversity of collective ideas without diminishing individual creativity.
        - *Relevance*: AI can enrich group creativity.
  - **Negative Influence**:
    - *Cited work*:
      - **H. Kumar et al. (2024)**:
        - Exposure to AI strategies may decrease originality and creative flexibility in subsequent tasks.
        - *Relevance*: Cautionary note on potential drawbacks of AI assistance.

### Communication and Information Sharing

- **Transactive Memory Systems (TMS) in Group Cognition**:
  - Shared understanding of knowledge distribution among group members.
    - *Cited works*:
      - **Wegner (1987); Yan et al. (2021)**: Foundational concepts for TMS and its role in efficient access and sharing of expertise.

- **AI as a Unique Knowledge Repository**:
  - *Cited work*:
    - **Bienefeld et al. (2023)**:
      - Observational study in an ICU setting with teams collaborating with an AI agent "Autovent."
      - Findings:
        - Higher-performing teams accessing AI knowledge correlated with new hypotheses and increased speaking-up behavior.
        - Accessing human teammate information negatively associated with these behaviors.
      - *Relevance*: AI may help overcome social barriers in information sharing and encourage proactive communication.

- **AI-Mediated Communication in Professional Settings**:
  - *Cited work*:
    - **Bastola et al. (2024)**:
      - Developed an LLM-based Smart Reply (LSR) system using ChatGPT for workplace interactions.
      - Participants managed multitasking scenarios while using LSR.
      - Findings:
        - Improved work performance and messaging efficiency.
        - Reduced cognitive load.
        - Concerns about appropriateness, accuracy, trust, and privacy.
      - *Relevance*: AI tools can facilitate collaboration but must address user experience challenges.

- **Additional Works Related to Communication and Information Sharing**:
  - *(Details not provided, but implied relevance to this section)*:
    - **Yang et al. (2024)**
    - **Ma et al. (2024)**
    - **Radivojevic et al. (2024)**
    - **Sidji et al. (2024)**
    - **Nishida et al. (2024)**
    - **Chuang et al. (2024)**

### Shared Mental Models

- **Understanding through Shared Mental Models**:
  - *Cited work*:
    - **Collins et al. (2024)**:
      - *(Specific context or findings not provided)*

### Cognitive Load

- **Influencing Cognitive Engagement with AI Recommendations**:
  - *Cited work*:
    - **Buçinca et al. (2021)**:
      - Investigated "cognitive forcing functions" in interface design to promote analytical engagement with AI.
      - Interventions included:
        - Requiring explicit requests for AI input.
        - Mandating initial independent decisions.
        - Introducing temporal delays.
      - Findings:
        - Reduced overreliance on incorrect AI recommendations.
        - Increased perceived cognitive load and decreased user satisfaction.
        - Greater benefits observed in individuals with high Need for Cognition (NFC).
      - *Relevance*: Interface design can modulate AI reliance but may introduce trade-offs in user experience and equity concerns.

---

## Decision-Making Output

### Consensus Formation

- **AI-Mediated Consensus Building**:
  - *Cited work*:
    - **Tessler et al. (2024)**:
      - Developed the "Habermas Machine" (HM), an LLM-based system to mediate human deliberation.
      - Process:
        - HM receives input statements from individuals.
        - Generates consensus statements aimed at maximizing group endorsement.
      - Findings:
        - AI-generated statements preferred over those by human mediators.
        - Rated higher in informativeness, clarity, and lack of bias.
        - Successfully incorporated minority opinions.
      - *Relevance*: AI can effectively facilitate consensus by articulating collective sentiment.

### Decision Accuracy and Complementarity

- **Leveraging Complementary Strengths of Humans and AI**:
  - *Cited work*:
    - **Rastogi et al. (2023)**:
      - Proposed a taxonomy to characterize differences in human and machine decision-making.
      - Framework aids in optimally combining human and AI capabilities.
      - *Relevance*: Theoretical basis for effective human-AI collaboration.

- **Improving Decision-Making through AI-Generated Aids**:
  - *Cited work*:
    - **Becker et al. (2022)**:
      - Demonstrated that AI-generated procedural instructions enhance human decision-making.
      - Emphasizes the importance of interpretability.
      - *Relevance*: Practical application of AI to support human decisions.

- **Enhancing Human Performance via Exposure to Superhuman AI**:
  - *Cited work*:
    - **Shin et al. (2023)**:
      - Exposure to superhuman AI in Go encourages novel strategy exploration.
      - Leads to improved decision-making and innovation.
      - *Relevance*: AI can inspire humans to surpass conventional thinking.

- **Challenges in Human-AI Team Dynamics**:
  - *Cited work*:
    - **Bennett et al. (2023)**:
      - Identified performance costs in both human-human and human-AI teams relative to benchmarks.
      - Human-human teams had advantages in collaborative conditions.
      - Advantage diminished in human-AI teams due to coordination difficulties.
      - *Relevance*: Highlights the need for improved coordination mechanisms in human-AI teams.

- **Adaptation and Reliance on AI Assistance**:
  - *Cited work*:
    - **Liang et al. (2022)**:
      - Humans learn to selectively rely on AI based on task difficulty.
      - Effective collaboration requires explicit feedback and training.
      - *Relevance*: Emphasizes the importance of support for optimal human-AI interaction.

---

## Trust, Risk, and Reliance

### Trust in AI

- **Influence of Confidence on Advice-Seeking and Integration**:
  - *Cited work*:
    - **Pescetelli & Yeung (2021)**:
      - Individuals more likely to seek advice when their confidence is low.
      - Tend to deviate from optimal Bayesian integration, using heuristic strategies.
      - *Relevance*: Confidence levels affect interactions with AI advice.

- **Context-Dependent Advice-Seeking Behaviors**:
  - *Cited work*:
    - **Carlebach & Yeung (2023)**:
      - When AI advisor reliability is unknown, individuals may seek advice even when confident.
      - Use own confidence as feedback to assess advisor quality.
      - *Relevance*: Highlights complexities in trust and advice utilization.

- **Adaptation Based on Perceived Performance Differences**:
  - *Cited work*:
    - **Liang et al. (2022)**:
      - Explicit performance comparisons influence reliance on AI.
      - Individuals adjust AI use based on task difficulty and accuracy perceptions.
      - *Relevance*: Trust influenced by perceived competence of AI.

- **Overestimation of AI Accuracy and Mitigation Strategies**:
  - *Cited work*:
    - **Steyvers et al. (2024)**:
      - Users overestimate AI accuracy when presented with lengthy default explanations.
      - Miscalibration mitigated by communicating AI's uncertainty.
      - *Relevance*: Importance of transparency in AI explanations.

- **Trust Dynamics in Human-AI Teams**:
  - *Cited work*:
    - **Cui & Yasseri (2024)**:
      - Trust crucial for collective intelligence in teams.
      - Factors affecting trust:
        - Perceived competence.
        - Benevolence.
        - Integrity of AI systems.
      - Anthropomorphism of AI can affect trust levels.
      - *Relevance*: Trust as a key factor in team performance with AI.

- **AI's Influence Despite Trust Levels**:
  - *Cited work*:
    - **Zvelebilova et al. (2024)**:
      - Teams may adopt AI suggestions even without full trust.
      - AI can shape team discourse and attention.
      - *Relevance*: AI impact on group cognition regardless of explicit trust.

### Utilization

- **Modulating AI Reliance Through Interface Design**:
  - *Cited work*:
    - **Buçinca et al. (2021)**:
      - Addressed overreliance on AI via "cognitive forcing functions" in interfaces.
      - Interventions reduced overreliance but increased complexity and decreased user preference.
      - Equity concerns due to varying benefits based on Need for Cognition.
      - *Relevance*: Balancing effective AI utilization with user experience.

### Responsibility

- **Attribution of Responsibility in Human-AI Collaboration**:
  - *Cited work*:
    - **Tsirtsis et al. (2024)**:
      - Studied responsibility judgments in semi-autonomous driving simulations.
      - Factors influencing judgments:
        - Unexpectedness of actions.
        - Counterfactual thinking.
        - Actual contribution to outcomes.
      - *Relevance*: Understanding responsibility allocation in shared-control scenarios.

- **Additional Work on Responsibility**:
  - *(Specific context not provided)*:
    - **Narayanan et al. (2023)**

### Risk

- **Considerations of Risk in Human-AI Interactions**:
  - *(Specific contexts not provided, but implied relevance to risks associated with AI in decision-making)*:
    - **Bhatia (2024)**
    - **Zhu et al. (2024)**

---