Book title: A Research Agenda for Group Dynamics

  
  

Our chapter: AI and Group Decision Making: An Information Processing Perspective

  
  

# Proposed Outline for chapter

  

## AI and Group Decision Making: An Information Processing Perspective

  

### Introduction: The Transforming Landscape of Group Decision-Making

  

- Definitions and importance of group decision-making

- Rise of AI in group decision-making

- Key overview papers

- Lai (2023) - *Overview of human-AI decision-making research design space*.

- Rastogi (2023) - *Taxonomy of human-ML complementarity*.

- Steyvers & Kumar (2024) - *Key challenges in AI-assisted decision making*.

- Burton et al. 2024 - How large language models can reshape collective intelligence

  

### Inputs

- group members

#### Are AI agents group members

- Lu - mix and match

- Kumar (2024) - differing perspectives

- McNeese et al. (2023)

#### AI roles

- Advisor, mediator, devil's advocate

- Tessler et al. (2024) - *AI helping humans find common ground*.
	- De 2024 - Supernotes: Driving Consensus in Crowd-Sourced Fact-Checking

- Chiang et al. (2024) - *LLM-powered devil's advocate in group decisions*.
- Carter 2024 - Integrating artificial intelligence into team decision-making: Toward a theory of AI–human team effectiveness

Marjieh 2024 - task allocation

- member characteristics

- organizational context

  
  

### Informational Processing

- Information search

- **Shared vs. Unshared Information**

- The hidden profile paradigm in AI-assisted groups.

- Gao et al. (2024) - *LLMs in agent-based modeling and simulation*.

- **Attention**

- Swaroop (2024) - *Attention allocation under time pressure*.

- Chiang et al. (2024) - *AI devil's advocate directing attention*.

- Communication; information sharing

- Yang et al. (2024) - *Talk2Care: AI in healthcare communication*.

- Bienefeld et al. (2023) - *Human-AI teaming in ICU settings*.

- Ma 2024 - Deliberation

- Sidji 2024

- Radivojevic (2024) - LLMs in group discourse

####  Shared Mental Models

- How AI contributes to shared mental models in groups.

- Collins 2024 - *Vision for human-AI thought partnership*.

####  Cognitive Load

- Buçinca et al. (2021) - Cognitive forcing functions to reduce overreliance

- Stadler (2024).-  Cognitive ease at a cost: LLMs reduce mental effort but compromise depth
- 
- Westby (2023) - Collective Intelligence in Human-AI Teams: A Bayesian Theory of Mind Approach

  

### Decision Making output

####  Use of AI reccomendations

- Subramonyam et al. (2024)- *Utilization of AI recommendations*.

####  Consensus formation

- Du et al. (2024) - *LLMs in collective problem-solving*.

- Tessler et al. (2024) - *AI helping humans find common ground*.

- Chuang et al. (2024) - *Wisdom of partisan crowds with LLMs*.

- Nishida 2024 - Conversational Agent Dynamics with Minority Opinion and Cognitive Conflict in Small-Group Decision-Making

####  Decision quality

- in comparison to human only groups

- Becker (2022) - Boosting Human Decision‑Making With Ai‑Generated Decision Aids

- Swaroop 2024

  

### Trust, Risk, and Reliance

- Trust in AI

- Factors that affect trust in AI during group decisions.

- Westphal et al. (2023) - *Decision control and explanations*.

- Koehl & Vangsness (2023) - *Measuring latent trust patterns in LLMs*.

- Banerjee (guidance)

- Reliance on AI

- Narayanan - *Value similarity and reliance on AI*.

- Tsirtsis (2024) - Responsibility judgement in ai-assisted decision making

####  Over vs. under utilization

- Hao 2024

- Bucina 2021

- Stadler 2024 - cognitive ease at a cost

####  Risk

- Bhatia 2024 - Exploring variability in risk taking with llms

- Zhu, Yan & Griffiths 2024 - Language Models Trained to do Arithmetic Predict Human Risky and Intertemporal Choice

  
  

### Cognitive Biases in Human-AI Decision Making

  

- **Amplification of Human Biases**

- How AI may reflect or exacerbate cognitive biases.

- Cheung et al. (2024) - *LLMs amplifying human biases in moral decisions*.

- Hagendorff et al. (2023) - *Intuitive behavior and reasoning biases in LLMs*.

- **Biases in AI Reasoning**

- Macmillan-Scott & Musolesi (2024) - *(Ir)rationality and cognitive biases in LLMs*.

- Suri et al. (2024) - *Decision heuristics in LLMs*.

- Nguyen (2024) - *Human bias in AI models*.

- **Mitigating Cognitive Biases**

- Strategies to identify and reduce biases in AI-assisted decisions.

- Rastogi et al. (2022) - *Role of cognitive biases in AI-assisted decision-making*.








# Alternative


  

## 1. Inputs: Information Acquisition and Sharing in Groups


This section examines how AI influences the information acquisition and sharing processes within groups.

### 1.1 AI-Augmented Information Search


- **Enhancements in Information Seeking:**

- How AI tools, such as large language models (LLMs), enhance information seeking and gathering.

- The role of AI in processing vast amounts of data to provide relevant information.

- **Potential Biases in AI-Assisted Search:**

- Risks of AI introducing biases during information retrieval.

- Influence of AI on the diversity and novelty of information accessed by group members.

- **Cited Papers:**

- Yang et al. (2024) - *Talk2Care: An LLM-Based Voice Assistant for Communication Between Healthcare Providers and Older Adults.*

- Hao et al. (2024) - *Exploring Collaborative Decision-Making: A Quasi-Experimental Study of Human and Generative AI Interaction.*

- Sun et al. (2024) - *Trusting the Search: Unraveling Human Trust in Health Information from Google and ChatGPT.*

- Zheng et al. (2024) - *DiscipLink: Augmenting Across-Disciplinary Literature Review with AI.*

- Ma et al. (2024) - *LLM-Empowered Deliberative AI for AI-Assisted Decision-Making.*

- Galesic et al. (2023) - *Beyond Collective Intelligence: Collective Adaptation.*

### 1.2 AI-Mediated Communication and Information Sharing


- **Impact on Communication Dynamics:**

- How AI agents facilitate or hinder communication within groups.

- The role of chatbots and virtual assistants in promoting information exchange.

- **AI as a Catalyst for Cognitive Diversity:**

- Enhancing cognitive diversity and information elaboration through AI-mediated communication.

- **Cited Papers:**

- Bienefeld et al. (2023) - *Human-AI Teaming: Leveraging Transactive Memory and Speaking Up for Enhanced Team Effectiveness.*

- Gurkan & Yan (2023) - *Chatbot Catalysts: Improving Team Decision-Making Through Cognitive Diversity and Information Elaboration.*

- Abdelnabi et al. (2023) - *LLM-Deliberation: Evaluating LLMs with Interactive Multi-Agent Negotiation Games.*

- Du et al. (2024) - *Large Language Models for Collective Problem-Solving: Insights into Group Consensus Decision-Making.*

- Zhang et al. (2024) - *Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology View.*

- Sidji et al. (2024) - *Human-AI Collaboration in Cooperative Games: A Study of Playing Codenames with an LLM Assistant.*

- Marijeh et al. (2024) - *Task Allocation in Teams as a Multi-Armed Bandit.*


### 1.3 AI's Influence on Information Sharing Patterns

  
- **Group Attention and Knowledge Distribution:**

- The impact of AI on group attention mechanisms and the distribution of knowledge within teams.

- How AI affects collective memory and recall processes.

- **Cited Papers:**

- Westby & Riedl (2023) - *Collective Intelligence in Human-AI Teams: A Bayesian Theory of Mind Approach.*

- Yan et al. (2021) - *Communication in Transactive Memory Systems: A Review and Multidimensional Network Perspective.*

- Hedley (2024) - *Division of Labour and Team Performance: Human-Human Teams Compared to Hybrid Human-Machine Teams.*

### 1.4 Biases, Trust, and Reliance in Information Acquisition

- **Influence on Trust and Bias Introduction:**
- How AI influences trust during information acquisition.
- The introduction of biases due to AI suggestions and recommendations.

- **Cognitive Biases and Anchoring Effects:**

- Examination of anchoring biases and how AI may amplify or mitigate them.

- **Cited Papers:**
- Choi et al. (2024) - *The LLM Effect: Are Humans Truly Using LLMs, or Are They Being Influenced by Them Instead?*

- Tjuatja et al. (2024) - *Do LLMs Exhibit Human-Like Response Biases? A Case Study in Survey Design.*

- Zhao et al. (2024) - *Risk and Prosocial Behavioural Cues Elicit Human-Like Response Patterns from AI Chatbots.*

- Swaroop et al. (2024) - *Accuracy-Time Tradeoffs in AI-Assisted Decision Making Under Time Pressure.*

- Suri et al. (2024) - *Do Large Language Models Show Decision Heuristics Similar to Humans?*

- Pataranutaporn et al. (2023) - *Influencing Human–AI Interaction by Priming Beliefs About AI Can Increase Perceived Trustworthiness, Empathy and Effectiveness.*

- Liu et al. (2021) - *Understanding the Effect of Out-of-Distribution Examples and Interactive Explanations on Human-AI Decision Making.*

- Zhou et al. (2024) - *Humans Mindlessly Treat AI Virtual Agents as Social Beings.*

- Carstens & Friess (2024) - *AI Within Online Discussions: Rational, Civil, Privileged?*



---


**1. Inputs: Information Acquisition and Sharing in Groups**

  

This section examines how AI influences the initial stages of group decision-making by impacting how groups search for, gather, and exchange information.

  

* **1.1 AI-Augmented Information Search:** How AI tools can enhance and potentially bias information seeking. Explore the impact on search strategies, information overload, and exploration-exploitation balance.

* (Yang et al., 2024) - Talk2Care: Using voice assistants for information collection.

* (Hao et al., 2024) - Generative AI for reducing cognitive burden in information gathering.

* (Sun et al., 2024) - Trust in health information from Google vs. ChatGPT.

* (Zheng et al., 2024) - DiscipLink: AI-assisted interdisciplinary information seeking.

* (Giannoccaro et al., 2020) - Exploring factors related to search in groups, comparing human-human teams and hybrid teams.

* (Bower et al., 2024) - Examining how expertise influences the cues used to judge knowledge, relating to information source evaluation in AI-assisted search.

* (Ashkinaze et al., 2024) - How exposure to AI-generated ideas impacts human idea generation and search for novel solutions.

  

* **1.2 AI-Mediated Communication and Information Sharing:** How AI impacts communication dynamics, information distribution, and transactive memory. Discuss the roles of AI as facilitators, mediators, and potential sources of bias.

* (Bienefeld et al., 2023) - Transactive memory and speaking up in human-AI teams.

* (Bastola et al., 2024) - LLM-based smart reply for enhancing collaborative performance.

* (Abdelnabi et al., 2023) - LLM-Deliberation: Information exchange in negotiation games.

* (Du et al., 2024) - LLMs for collective problem-solving and information exchange.

* (Ma et al., 2024) - Human-AI deliberation in shared workspace tasks.

* (Gurkan & Yan, 2023) - Chatbots as catalysts for cognitive diversity and information elaboration.

* (Yan et al., 2021) - Review of communication in transactive memory systems.

* (Duan et al., 2024) - Using LLMs for milestone detection in group discussions, which could influence information sharing and focus.

* (Zhou & Gorman, 2024) - Impact of communication timing and sequencing in human-AI vs. all-human teams, relating to information flow and attention.

  
  

* **1.3 Trust and Bias in Information Acquisition:** How AI influences trust, introduces biases (e.g., anchoring, confirmation bias), and impacts reliance on different information sources. Consider the role of AI explanations and transparency in shaping trust.

* (Choi et al., 2024) - The LLM Effect: Influence and anchoring bias from LLMs.

* (Zhao et al., 2024) - AI chatbots eliciting human-like response patterns to risk.

* (Tjuatja et al., 2024) - Response biases in LLMs compared to humans in survey design.

* (Liu et al., 2021) - Out-of-distribution examples and explanations affecting trust.

* (Yax et al., 2024) - Reasoning biases in humans and machines.

* (Pataranutaporn et al., 2023) - Priming beliefs about AI to increase trust.

* (Zhou et al., 2024) - Investigating whether AI agents are treated as social beings.

* (Carstens & Friess, 2024) - Focus on deliberative norms and potential bias in AI tools for online discussions.

* (Hu et al., 2024) - Exploring social identity biases in LLMs and their potential impact on information sharing and trust.